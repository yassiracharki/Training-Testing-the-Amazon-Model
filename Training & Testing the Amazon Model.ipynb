{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5339021,"sourceType":"datasetVersion","datasetId":2078011},{"sourceId":61184,"sourceType":"modelInstanceVersion","modelInstanceId":51145}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yacharki/training-testing-the-amazon-model?scriptVersionId=191565891\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Downloads\n!pip install contractions\n!pip install textsearch\n!pip install tqdm\n\nimport nltk\nnltk.download('punkt')\n\n# Fundamental classes\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\n\n# Time\nimport time\nimport datetime\n\n# Preprocessing\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom sklearn.preprocessing import LabelEncoder\nimport contractions\nfrom bs4 import BeautifulSoup\nimport re\nimport tqdm\nimport unicodedata\n\nseed = 3541\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:14:01.244309Z","iopub.execute_input":"2024-06-05T13:14:01.245337Z","iopub.status.idle":"2024-06-05T13:14:37.4098Z","shell.execute_reply.started":"2024-06-05T13:14:01.245294Z","shell.execute_reply":"2024-06-05T13:14:37.408656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dummy loss to bypass the error during model loading\ndef dummy_loss(y_true, y_pred):\n    return tf.reduce_mean(y_pred - y_true)\n\n# Loading the model Trained on Amazon reviews\nmodelAmazon = keras.models.load_model(\n    '/kaggle/input/pre-trained-model-binary-cnn-nlp-amazon-reviews/tensorflow1/pre_trained_sentiment_analysis_cnn_model_amazon_reviews/1/Binary_Classification_86_Amazon_Reviews_CNN.h5',\n    compile=False\n)\n\n# Compile the model with the correct loss function and reduction\nmodelAmazon.compile(\n    optimizer='adam',\n    loss=keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE),\n    metrics=['accuracy']\n)\n\n# Loading Amazon test data\ndataset_test_Amazon = pd.read_csv('/kaggle/input/amazon-reviews-for-sa-binary-negative-positive-csv/amazon_review_sa_binary_csv/test.csv')\n\n# Loading Amazon train data (to be used on the label encoder)\ndataset_train_Amazon = pd.read_csv('/kaggle/input/amazon-reviews-for-sa-binary-negative-positive-csv/amazon_review_sa_binary_csv/train.csv')\n\n# Shuffling the Test Data\ntest_Amazon = dataset_test_Amazon.sample(frac=1)\ntrain_Amazon = dataset_train_Amazon.sample(frac=1)\n\n# Taking a tiny portion of the database (because it will only be used on the label encoder)\ntrain_Amazon = dataset_train_Amazon.iloc[:100, :]\n\n# Taking only necessary columns\ny_test_Amazon = test_Amazon['class_index'].values\nX_train_Amazon = train_Amazon['review_text'].values\ny_train_Amazon = train_Amazon['class_index'].values\n\n# Preprocess corpus function\ndef pre_process_corpus(corpus):\n    processed_corpus = []\n    for doc in tqdm.tqdm(corpus):\n        doc = contractions.fix(doc)\n        doc = BeautifulSoup(doc, \"html.parser\").get_text()\n        doc = unicodedata.normalize('NFKD', doc).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n        doc = doc.lower()\n        doc = doc.strip()\n        processed_corpus.append(doc)\n    return processed_corpus\n\n# Preprocessing the Data\nX_test_Amazon = pre_process_corpus(test_Amazon['review_text'].values)\nX_train_Amazon = pre_process_corpus(X_train_Amazon)\n\n# Creating and Fitting the Tokenizer\nt = Tokenizer(oov_token='<UNK>')\nt.fit_on_texts(X_train_Amazon)\nt.word_index['<PAD>'] = 0\n\n# Transforming text to sequences \nX_test_Amazon = t.texts_to_sequences(X_test_Amazon)\nX_train_Amazon = t.texts_to_sequences(X_train_Amazon)\n\n# Padding the transformed text (sentences) to maximum length of 220\nX_test_Amazon = sequence.pad_sequences(X_test_Amazon, maxlen=220)\nX_train_Amazon = sequence.pad_sequences(X_train_Amazon, maxlen=220)\n\n# Creating and Fitting the label encoder\nle = LabelEncoder()\nnum_classes = 2  # positive -> 1, negative -> 0\ny_train_Amazon = le.fit_transform(y_train_Amazon)\n\n# Transforming the labels\ny_test_Amazon = le.transform(y_test_Amazon)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-05T13:14:37.411942Z","iopub.execute_input":"2024-06-05T13:14:37.412277Z","iopub.status.idle":"2024-06-05T13:16:32.395143Z","shell.execute_reply.started":"2024-06-05T13:14:37.412247Z","shell.execute_reply":"2024-06-05T13:16:32.394125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the models\n\n#Testing Amazon Classifier on Amazon Test Data\nprint(\" Testing Amazon Classifier on Amazon Test Data\")\nscores = modelAmazon.evaluate(X_test_Amazon, y_test_Amazon, verbose=1)\nprint(\"Accuracy: %.2f%% /n\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:16:32.396242Z","iopub.execute_input":"2024-06-05T13:16:32.396527Z","iopub.status.idle":"2024-06-05T13:16:58.581719Z","shell.execute_reply.started":"2024-06-05T13:16:32.396503Z","shell.execute_reply":"2024-06-05T13:16:58.580715Z"},"trusted":true},"execution_count":null,"outputs":[]}]}